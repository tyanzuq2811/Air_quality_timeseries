{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176c9ec9",
   "metadata": {},
   "source": [
    "# Q2: Baseline H·ªìi Quy - Gi·∫£i Th√≠ch & Ph√¢n T√≠ch\n",
    "\n",
    "Notebook n√†y gi·∫£i th√≠ch c√°c kh√°i ni·ªám quan tr·ªçng trong baseline h·ªìi quy cho d·ª± b√°o PM2.5:\n",
    "\n",
    "1. **V√¨ sao lag 24h c√≥ √Ω nghƒ©a?**\n",
    "2. **V√¨ sao ph·∫£i chia theo th·ªùi gian b·∫±ng cutoff?**\n",
    "3. **Ph√¢n bi·ªát RMSE v√† MAE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fe4e1",
   "metadata": {},
   "source": [
    "## 1. V√¨ sao Lag 24h th∆∞·ªùng c√≥ √Ω nghƒ©a?\n",
    "\n",
    "### L√Ω thuy·∫øt:\n",
    "\n",
    "**Lag 24 gi·ªù (1 ng√†y) c√≥ √Ω nghƒ©a v√¨:**\n",
    "\n",
    "1. **Nh·ªãp sinh ho·∫°t theo ng√†y (Daily Activity Cycle):**\n",
    "   - Ho·∫°t ƒë·ªông con ng∆∞·ªùi c√≥ chu k·ª≥ 24h: giao th√¥ng, c√¥ng nghi·ªáp, sinh ho·∫°t\n",
    "   - Gi·ªù cao ƒëi·ªÉm s√°ng/chi·ªÅu ‚Üí √¥ nhi·ªÖm tƒÉng theo pattern\n",
    "   - ƒê√™m khuya ‚Üí √≠t ho·∫°t ƒë·ªông ‚Üí √¥ nhi·ªÖm gi·∫£m\n",
    "   - Pattern n√†y l·∫∑p l·∫°i m·ªói ng√†y ‚Üí PM2.5 h√¥m nay t∆∞∆°ng t·ª± PM2.5 c√πng gi·ªù h√¥m qua\n",
    "\n",
    "2. **ƒêi·ªÅu ki·ªán kh√≠ t∆∞·ª£ng l·∫∑p l·∫°i theo chu k·ª≥ ng√†y:**\n",
    "   - Nhi·ªát ƒë·ªô, √°p su·∫•t, ƒë·ªô ·∫©m c√≥ chu k·ª≥ ng√†y-ƒë√™m\n",
    "   - H∆∞·ªõng gi√≥, t·ªëc ƒë·ªô gi√≥ th∆∞·ªùng c√≥ pattern h√†ng ng√†y\n",
    "   - ƒêi·ªÅu ki·ªán kh√≠ t∆∞·ª£ng t∆∞∆°ng t·ª± ‚Üí kh·∫£ nƒÉng khu·∫øch t√°n √¥ nhi·ªÖm t∆∞∆°ng t·ª±\n",
    "\n",
    "3. **Hi·ªán t∆∞·ª£ng PBL (Planetary Boundary Layer):**\n",
    "   - Chi·ªÅu cao l·ªõp bi√™n h√†nh tinh thay ƒë·ªïi theo chu k·ª≥ ng√†y\n",
    "   - Ban ng√†y: PBL cao ‚Üí √¥ nhi·ªÖm khu·∫øch t√°n\n",
    "   - Ban ƒë√™m: PBL th·∫•p ‚Üí √¥ nhi·ªÖm t·∫≠p trung\n",
    "   - Chu k·ª≥ n√†y l·∫∑p l·∫°i m·ªói 24h\n",
    "\n",
    "### Minh h·ªça th·ª±c nghi·ªám:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2670ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eb31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from src.classification_library import load_beijing_air_quality, clean_air_quality_df\n",
    "\n",
    "RAW_ZIP_PATH = '../data/raw/PRSA2017_Data_20130301-20170228.zip'\n",
    "df_raw = load_beijing_air_quality(use_ucimlrepo=False, raw_zip_path=RAW_ZIP_PATH)\n",
    "df = clean_air_quality_df(df_raw)\n",
    "\n",
    "# Ch·ªçn m·ªôt tr·∫°m\n",
    "STATION = 'Aotizhongxin'\n",
    "df_station = df[df['station'] == STATION].sort_values('datetime').reset_index(drop=True)\n",
    "print(f\"Data shape: {df_station.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o lag features\n",
    "df_lag = df_station[['datetime', 'PM2.5']].copy()\n",
    "df_lag['hour'] = df_lag['datetime'].dt.hour\n",
    "\n",
    "# T·∫°o nhi·ªÅu lag kh√°c nhau\n",
    "lags = [1, 6, 12, 24, 48, 72, 168]  # 1h, 6h, 12h, 1day, 2day, 3day, 1week\n",
    "for lag in lags:\n",
    "    df_lag[f'PM25_lag{lag}'] = df_lag['PM2.5'].shift(lag)\n",
    "\n",
    "# T√≠nh correlation\n",
    "print(\"=\" * 60)\n",
    "print(\"CORRELATION PM2.5(t) v·ªõi c√°c LAG\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "correlations = {}\n",
    "for lag in lags:\n",
    "    corr = df_lag['PM2.5'].corr(df_lag[f'PM25_lag{lag}'])\n",
    "    correlations[f'Lag {lag}h'] = corr\n",
    "    print(f\"Lag {lag:3d}h: {corr:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "lag_names = list(correlations.keys())\n",
    "lag_values = list(correlations.values())\n",
    "colors = ['red' if '24' in name else 'steelblue' for name in lag_names]\n",
    "ax.bar(lag_names, lag_values, color=colors, alpha=0.7)\n",
    "ax.set_ylabel('Correlation', fontsize=12)\n",
    "ax.set_title('Correlation PM2.5(t) v·ªõi c√°c Lag kh√°c nhau', fontsize=13, fontweight='bold')\n",
    "ax.axhline(y=0.5, color='green', linestyle='--', alpha=0.5, label='Threshold 0.5')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è NH·∫¨N X√âT:\")\n",
    "print(f\"‚úÖ Lag 24h c√≥ correlation = {correlations['Lag 24h']:.3f}\")\n",
    "print(\"‚Üí R·∫•t cao, cho th·∫•y PM2.5 c√≥ chu k·ª≥ ng√†y r√µ r√†ng\")\n",
    "print(\"‚Üí Lag 24h l√† feature QUAN TR·ªåNG NH·∫§T cho m√¥ h√¨nh h·ªìi quy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minh h·ªça: PM2.5 theo gi·ªù trong ng√†y\n",
    "df_hourly = df_station.copy()\n",
    "df_hourly['hour'] = df_hourly['datetime'].dt.hour\n",
    "\n",
    "# T√≠nh trung b√¨nh PM2.5 theo gi·ªù\n",
    "hourly_pattern = df_hourly.groupby('hour')['PM2.5'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(hourly_pattern['hour'], hourly_pattern['mean'], marker='o', linewidth=2, \n",
    "        markersize=8, color='darkblue', label='Mean PM2.5')\n",
    "ax.fill_between(hourly_pattern['hour'], \n",
    "                 hourly_pattern['mean'] - hourly_pattern['std'],\n",
    "                 hourly_pattern['mean'] + hourly_pattern['std'],\n",
    "                 alpha=0.3, color='lightblue', label='¬±1 std')\n",
    "ax.set_xlabel('Gi·ªù trong ng√†y', fontsize=12)\n",
    "ax.set_ylabel('PM2.5 (Œºg/m¬≥)', fontsize=12)\n",
    "ax.set_title('Pattern PM2.5 theo gi·ªù trong ng√†y (Average)', fontsize=13, fontweight='bold')\n",
    "ax.set_xticks(range(0, 24, 2))\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è NH·∫¨N X√âT:\")\n",
    "print(\"‚úÖ PM2.5 c√≥ pattern r√µ r√†ng theo gi·ªù trong ng√†y\")\n",
    "print(f\"   - Cao ƒëi·ªÉm: gi·ªù {hourly_pattern.loc[hourly_pattern['mean'].idxmax(), 'hour']:.0f}h\")\n",
    "print(f\"   - Th·∫•p ƒëi·ªÉm: gi·ªù {hourly_pattern.loc[hourly_pattern['mean'].idxmin(), 'hour']:.0f}h\")\n",
    "print(\"‚Üí ƒê√¢y l√† l√Ω do v√¨ sao lag 24h r·∫•t c√≥ √Ω nghƒ©a!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d56bbc",
   "metadata": {},
   "source": [
    "## 2. V√¨ sao ph·∫£i chia theo th·ªùi gian b·∫±ng CUTOFF?\n",
    "\n",
    "### L√Ω thuy·∫øt:\n",
    "\n",
    "**CUTOFF (temporal split) l√† THI·∫æT Y·∫æU trong time series ƒë·ªÉ:**\n",
    "\n",
    "1. **Tr√°nh Data Leakage (R√≤ r·ªâ d·ªØ li·ªáu):**\n",
    "   - N·∫øu d√πng random split ‚Üí model c√≥ th·ªÉ \"nh√¨n th·∫•y t∆∞∆°ng lai\"\n",
    "   - V√≠ d·ª•: train tr√™n 2017-03-01, test tr√™n 2017-02-15 ‚Üí kh√¥ng th·ª±c t·∫ø!\n",
    "   - Trong th·ª±c t·∫ø, ch√∫ng ta KH√îNG TH·ªÇ d√πng d·ªØ li·ªáu t∆∞∆°ng lai ƒë·ªÉ d·ª± ƒëo√°n qu√° kh·ª©\n",
    "\n",
    "2. **ƒê√°nh gi√° ƒë√∫ng kh·∫£ nƒÉng generalization:**\n",
    "   - Model c·∫ßn d·ª± ƒëo√°n t·ªët tr√™n d·ªØ li·ªáu CH∆ØA TH·∫§Y v√† ·ªü T∆Ø∆†NG LAI\n",
    "   - Random split ‚Üí performance ·∫£o, kh√¥ng ph·∫£n √°nh kh·∫£ nƒÉng th·ª±c t·∫ø\n",
    "   - Temporal split ‚Üí performance th·∫≠t, ƒë√°nh gi√° ƒë√∫ng model\n",
    "\n",
    "3. **M√¥ ph·ªèng production environment:**\n",
    "   - Khi deploy, model s·∫Ω d·ª± ƒëo√°n t∆∞∆°ng lai d·ª±a tr√™n qu√° kh·ª©\n",
    "   - Train/test split ph·∫£i gi·ªëng v·ªõi c√°ch model ƒë∆∞·ª£c d√πng th·ª±c t·∫ø\n",
    "\n",
    "### Minh h·ªça Data Leakage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc41775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Chu·∫©n b·ªã data v·ªõi lag features\n",
    "df_model = df_station[['datetime', 'PM2.5', 'TEMP', 'PRES', 'DEWP', 'WSPM']].copy()\n",
    "df_model['PM25_lag1'] = df_model['PM2.5'].shift(1)\n",
    "df_model['PM25_lag24'] = df_model['PM2.5'].shift(24)\n",
    "df_model['hour'] = df_model['datetime'].dt.hour\n",
    "df_model['dayofweek'] = df_model['datetime'].dt.dayofweek\n",
    "df_model = df_model.dropna()\n",
    "\n",
    "feature_cols = ['PM25_lag1', 'PM25_lag24', 'TEMP', 'PRES', 'DEWP', 'WSPM', 'hour', 'dayofweek']\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['PM2.5']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SO S√ÅNH: RANDOM SPLIT vs TEMPORAL SPLIT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Method 1: Random Split (SAI!)\n",
    "X_train_rand, X_test_rand, y_train_rand, y_test_rand = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model_rand = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)\n",
    "model_rand.fit(X_train_rand, y_train_rand)\n",
    "y_pred_rand = model_rand.predict(X_test_rand)\n",
    "\n",
    "rmse_rand = np.sqrt(mean_squared_error(y_test_rand, y_pred_rand))\n",
    "mae_rand = mean_absolute_error(y_test_rand, y_pred_rand)\n",
    "r2_rand = r2_score(y_test_rand, y_pred_rand)\n",
    "\n",
    "print(\"\\n1. RANDOM SPLIT (‚ùå SAI - c√≥ leakage):\")\n",
    "print(f\"   RMSE: {rmse_rand:.2f}\")\n",
    "print(f\"   MAE:  {mae_rand:.2f}\")\n",
    "print(f\"   R¬≤:   {r2_rand:.4f}\")\n",
    "\n",
    "# Method 2: Temporal Split (ƒê√öNG!)\n",
    "cutoff_date = pd.Timestamp('2017-01-01')\n",
    "train_mask = df_model['datetime'] < cutoff_date\n",
    "test_mask = df_model['datetime'] >= cutoff_date\n",
    "\n",
    "X_train_temp = X[train_mask]\n",
    "X_test_temp = X[test_mask]\n",
    "y_train_temp = y[train_mask]\n",
    "y_test_temp = y[test_mask]\n",
    "\n",
    "model_temp = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)\n",
    "model_temp.fit(X_train_temp, y_train_temp)\n",
    "y_pred_temp = model_temp.predict(X_test_temp)\n",
    "\n",
    "rmse_temp = np.sqrt(mean_squared_error(y_test_temp, y_pred_temp))\n",
    "mae_temp = mean_absolute_error(y_test_temp, y_pred_temp)\n",
    "r2_temp = r2_score(y_test_temp, y_pred_temp)\n",
    "\n",
    "print(\"\\n2. TEMPORAL SPLIT (‚úÖ ƒê√öNG - kh√¥ng leakage):\")\n",
    "print(f\"   RMSE: {rmse_temp:.2f}\")\n",
    "print(f\"   MAE:  {mae_temp:.2f}\")\n",
    "print(f\"   R¬≤:   {r2_temp:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PH√ÇN T√çCH S·ª∞ KH√ÅC BI·ªÜT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Ch√™nh l·ªách RMSE: {abs(rmse_rand - rmse_temp):.2f}\")\n",
    "print(f\"Ch√™nh l·ªách MAE:  {abs(mae_rand - mae_temp):.2f}\")\n",
    "print(f\"Ch√™nh l·ªách R¬≤:   {abs(r2_rand - r2_temp):.4f}\")\n",
    "\n",
    "if rmse_rand < rmse_temp:\n",
    "    print(\"\\n‚ö†Ô∏è K·∫æT LU·∫¨N:\")\n",
    "    print(\"‚ùå Random split cho k·∫øt qu·∫£ ƒê·∫∏P H∆†N (RMSE th·∫•p h∆°n)\")\n",
    "    print(\"   ‚Üí Nh∆∞ng ƒë√¢y l√† k·∫øt qu·∫£ GI·∫¢ do leakage!\")\n",
    "    print(\"   ‚Üí Model ƒë√£ 'l√©n nh√¨n' t∆∞∆°ng lai trong qu√° tr√¨nh train\")\n",
    "    print(\"   ‚Üí Khi deploy th·ª±c t·∫ø, performance s·∫Ω GI·∫¢M nh∆∞ temporal split\")\n",
    "    print(\"\\n‚úÖ Temporal split cho performance TH·∫¨T, d√π th·∫•p h∆°n\")\n",
    "    print(\"   ‚Üí ƒê√¢y m·ªõi l√† kh·∫£ nƒÉng th·ª±c s·ª± c·ªßa model\")\n",
    "    print(\"   ‚Üí N√™n LU√îN d√πng temporal split cho time series!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c220d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize split methods\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot 1: Temporal split visualization\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(df_model[train_mask]['datetime'], df_model[train_mask]['PM2.5'], \n",
    "            s=1, alpha=0.5, color='blue', label='Train')\n",
    "ax1.scatter(df_model[test_mask]['datetime'], df_model[test_mask]['PM2.5'], \n",
    "            s=1, alpha=0.5, color='red', label='Test')\n",
    "ax1.axvline(x=cutoff_date, color='green', linestyle='--', linewidth=2, label=f'Cutoff: {cutoff_date.date()}')\n",
    "ax1.set_ylabel('PM2.5', fontsize=11)\n",
    "ax1.set_title('‚úÖ TEMPORAL SPLIT - Train tr∆∞·ªõc cutoff, Test sau cutoff', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Random split visualization (to show the problem)\n",
    "ax2 = axes[1]\n",
    "df_model_indexed = df_model.reset_index(drop=True)\n",
    "train_indices_rand = X_train_rand.index\n",
    "test_indices_rand = X_test_rand.index\n",
    "ax2.scatter(df_model_indexed.loc[train_indices_rand, 'datetime'], \n",
    "            df_model_indexed.loc[train_indices_rand, 'PM2.5'], \n",
    "            s=1, alpha=0.5, color='blue', label='Train (scattered)')\n",
    "ax2.scatter(df_model_indexed.loc[test_indices_rand, 'datetime'], \n",
    "            df_model_indexed.loc[test_indices_rand, 'PM2.5'], \n",
    "            s=1, alpha=0.5, color='red', label='Test (scattered)')\n",
    "ax2.set_ylabel('PM2.5', fontsize=11)\n",
    "ax2.set_xlabel('Time', fontsize=11)\n",
    "ax2.set_title('‚ùå RANDOM SPLIT - Train/Test xen k·∫Ω (c√≥ leakage!)', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è NH·∫¨N X√âT:\")\n",
    "print(\"V·ªõi random split, train v√† test XEN K·∫º nhau theo th·ªùi gian\")\n",
    "print(\"‚Üí Model c√≥ th·ªÉ h·ªçc pattern t·ª´ 't∆∞∆°ng lai' (test set) th√¥ng qua lag features\")\n",
    "print(\"‚Üí Performance cao gi·∫£ t·∫°o, KH√îNG ph·∫£n √°nh kh·∫£ nƒÉng d·ª± b√°o th·ª±c t·∫ø\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e67cb4b",
   "metadata": {},
   "source": [
    "## 3. Ph√¢n bi·ªát RMSE v√† MAE\n",
    "\n",
    "### L√Ω thuy·∫øt:\n",
    "\n",
    "**MAE (Mean Absolute Error):**\n",
    "- $MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$\n",
    "- Trung b√¨nh c·ªßa **tr·ªã tuy·ªát ƒë·ªëi** sai s·ªë\n",
    "- ƒê·ªëi x·ª≠ **b√¨nh ƒë·∫≥ng** v·ªõi m·ªçi sai s·ªë\n",
    "- D·ªÖ hi·ªÉu: \"Trung b√¨nh model sai bao nhi√™u?\"\n",
    "\n",
    "**RMSE (Root Mean Squared Error):**\n",
    "- $RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}$\n",
    "- CƒÉn b·∫≠c 2 c·ªßa trung b√¨nh **b√¨nh ph∆∞∆°ng** sai s·ªë\n",
    "- **Ph·∫°t n·∫∑ng** sai s·ªë l·ªõn (do b√¨nh ph∆∞∆°ng)\n",
    "- Nh·∫°y c·∫£m v·ªõi outliers v√† spike\n",
    "\n",
    "**Khi n√†o RMSE cao h∆°n MAE nhi·ªÅu?**\n",
    "- Khi c√≥ **spike** (gi√° tr·ªã b·∫•t th∆∞·ªùng)\n",
    "- Khi d·ª± b√°o **sai m·∫°nh** ·ªü m·ªôt s·ªë th·ªùi ƒëi·ªÉm\n",
    "- Khi ph√¢n ph·ªëi sai s·ªë **kh√¥ng ƒë·ªìng ƒë·ªÅu** (c√≥ v√†i ƒëi·ªÉm sai r·∫•t l·ªõn)\n",
    "\n",
    "### Minh h·ªça:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dba82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S·ª≠ d·ª•ng predictions t·ª´ temporal split\n",
    "errors = y_test_temp.values - y_pred_temp\n",
    "\n",
    "mae_calc = np.mean(np.abs(errors))\n",
    "rmse_calc = np.sqrt(np.mean(errors**2))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PH√ÇN T√çCH RMSE vs MAE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MAE:  {mae_calc:.2f}  (trung b√¨nh sai s·ªë)\")\n",
    "print(f\"RMSE: {rmse_calc:.2f}  (ph·∫°t n·∫∑ng sai s·ªë l·ªõn)\")\n",
    "print(f\"RMSE/MAE ratio: {rmse_calc/mae_calc:.3f}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è NH·∫¨N X√âT:\")\n",
    "if rmse_calc / mae_calc > 1.5:\n",
    "    print(\"‚ùå RMSE >> MAE ‚Üí c√≥ nhi·ªÅu sai s·ªë L·ªöN ho·∫∑c SPIKE\")\n",
    "    print(\"   ‚Üí Model d·ª± ƒëo√°n SAI M·∫†NH ·ªü m·ªôt s·ªë th·ªùi ƒëi·ªÉm\")\n",
    "    print(\"   ‚Üí C·∫ßn c·∫£i thi·ªán model ho·∫∑c x·ª≠ l√Ω outliers\")\n",
    "elif rmse_calc / mae_calc > 1.2:\n",
    "    print(\"‚ö†Ô∏è RMSE > MAE (b√¨nh th∆∞·ªùng) ‚Üí c√≥ v√†i sai s·ªë l·ªõn h∆°n\")\n",
    "    print(\"   ‚Üí Ph√¢n ph·ªëi sai s·ªë kh√¥ng ho√†n to√†n ƒë·ªìng ƒë·ªÅu\")\n",
    "else:\n",
    "    print(\"‚úÖ RMSE ‚âà MAE ‚Üí ph√¢n ph·ªëi sai s·ªë kh√° ƒë·ªìng ƒë·ªÅu\")\n",
    "    print(\"   ‚Üí Model d·ª± ƒëo√°n ·ªïn ƒë·ªãnh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da13663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize error distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Error distribution histogram\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(errors, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax1.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero error')\n",
    "ax1.axvline(x=mae_calc, color='green', linestyle='--', linewidth=2, label=f'MAE={mae_calc:.1f}')\n",
    "ax1.axvline(x=-mae_calc, color='green', linestyle='--', linewidth=2)\n",
    "ax1.set_xlabel('Error (actual - predicted)', fontsize=11)\n",
    "ax1.set_ylabel('Frequency', fontsize=11)\n",
    "ax1.set_title('Ph√¢n ph·ªëi SAI S·ªê', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Absolute errors\n",
    "ax2 = axes[0, 1]\n",
    "abs_errors = np.abs(errors)\n",
    "ax2.hist(abs_errors, bins=50, color='coral', alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(x=mae_calc, color='blue', linestyle='--', linewidth=2, label=f'MAE={mae_calc:.1f}')\n",
    "ax2.axvline(x=rmse_calc, color='red', linestyle='--', linewidth=2, label=f'RMSE={rmse_calc:.1f}')\n",
    "ax2.set_xlabel('|Error|', fontsize=11)\n",
    "ax2.set_ylabel('Frequency', fontsize=11)\n",
    "ax2.set_title('Ph√¢n ph·ªëi SAI S·ªê TUY·ªÜT ƒê·ªêI', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Squared errors\n",
    "ax3 = axes[1, 0]\n",
    "squared_errors = errors**2\n",
    "ax3.hist(squared_errors, bins=50, color='orange', alpha=0.7, edgecolor='black')\n",
    "ax3.axvline(x=rmse_calc**2, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'MSE={rmse_calc**2:.1f}')\n",
    "ax3.set_xlabel('Error¬≤', fontsize=11)\n",
    "ax3.set_ylabel('Frequency', fontsize=11)\n",
    "ax3.set_title('Ph√¢n ph·ªëi SAI S·ªê B√åNH PH∆Ø∆†NG (nh·∫•n m·∫°nh spike)', fontsize=12, fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Time series of absolute errors\n",
    "ax4 = axes[1, 1]\n",
    "test_dates = df_model[test_mask]['datetime'].values\n",
    "ax4.plot(test_dates, abs_errors, linewidth=0.8, alpha=0.7, color='purple')\n",
    "ax4.axhline(y=mae_calc, color='blue', linestyle='--', linewidth=2, label=f'MAE={mae_calc:.1f}')\n",
    "ax4.axhline(y=rmse_calc, color='red', linestyle='--', linewidth=2, label=f'RMSE={rmse_calc:.1f}')\n",
    "ax4.set_xlabel('Time', fontsize=11)\n",
    "ax4.set_ylabel('|Error|', fontsize=11)\n",
    "ax4.set_title('SAI S·ªê theo TH·ªúI GIAN', fontsize=12, fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ph√¢n t√≠ch: T√¨m c√°c ƒëi·ªÉm c√≥ sai s·ªë l·ªõn\n",
    "large_error_threshold = np.percentile(abs_errors, 95)  # top 5% sai s·ªë\n",
    "large_error_mask = abs_errors > large_error_threshold\n",
    "n_large_errors = large_error_mask.sum()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PH√ÇN T√çCH SAI S·ªê L·ªöN (top 5%)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Ng∆∞·ª°ng sai s·ªë l·ªõn: {large_error_threshold:.2f}\")\n",
    "print(f\"S·ªë ƒëi·ªÉm c√≥ sai s·ªë l·ªõn: {n_large_errors} / {len(abs_errors)} ({n_large_errors/len(abs_errors)*100:.1f}%)\")\n",
    "print(f\"\\nƒê√≥ng g√≥p c·ªßa top 5% sai s·ªë v√†o:\")\n",
    "print(f\"  - MAE:  {np.mean(abs_errors[large_error_mask])/mae_calc:.2f}x\")\n",
    "print(f\"  - MSE:  {np.mean(squared_errors[large_error_mask])/(rmse_calc**2):.2f}x\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è K·∫æT LU·∫¨N v·ªÅ RMSE vs MAE:\")\n",
    "contribution_ratio = np.mean(squared_errors[large_error_mask])/(rmse_calc**2)\n",
    "if contribution_ratio > 2:\n",
    "    print(\"‚ùå Top 5% sai s·ªë L·ªöN ƒë√≥ng g√≥p R·∫§T NHI·ªÄU v√†o RMSE\")\n",
    "    print(\"   ‚Üí RMSE cao h∆°n MAE ƒë√°ng k·ªÉ\")\n",
    "    print(\"   ‚Üí Model c√≥ xu h∆∞·ªõng d·ª± b√°o SAI M·∫†NH ·ªü m·ªôt s·ªë spike/outlier\")\n",
    "    print(\"   ‚Üí N√™n t·∫≠p trung c·∫£i thi·ªán model t·∫°i c√°c ƒëi·ªÉm n√†y\")\n",
    "else:\n",
    "    print(\"‚úÖ Sai s·ªë ph√¢n b·ªë t∆∞∆°ng ƒë·ªëi ƒë·ªÅu\")\n",
    "    print(\"   ‚Üí RMSE v√† MAE ƒë·ªÅu ph·∫£n √°nh t·ªët performance c·ªßa model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d5e8b",
   "metadata": {},
   "source": [
    "## üìù T√ìM T·∫ÆT Q2\n",
    "\n",
    "### 1. V√¨ sao Lag 24h c√≥ √Ω nghƒ©a?\n",
    "‚úÖ **3 l√Ω do ch√≠nh:**\n",
    "- Nh·ªãp sinh ho·∫°t con ng∆∞·ªùi c√≥ chu k·ª≥ 24h (giao th√¥ng, c√¥ng nghi·ªáp)\n",
    "- ƒêi·ªÅu ki·ªán kh√≠ t∆∞·ª£ng l·∫∑p l·∫°i theo chu k·ª≥ ng√†y-ƒë√™m\n",
    "- Hi·ªán t∆∞·ª£ng PBL (l·ªõp bi√™n h√†nh tinh) thay ƒë·ªïi theo chu k·ª≥ ng√†y\n",
    "\n",
    "‚Üí **PM2.5 c√πng gi·ªù h√¥m qua l√† predictor t·ªët nh·∫•t cho PM2.5 h√¥m nay**\n",
    "\n",
    "### 2. V√¨ sao ph·∫£i chia theo cutoff?\n",
    "‚úÖ **Tr√°nh data leakage:**\n",
    "- Random split ‚Üí model \"nh√¨n th·∫•y t∆∞∆°ng lai\" ‚Üí performance gi·∫£\n",
    "- Temporal split ‚Üí model ch·ªâ h·ªçc t·ª´ qu√° kh·ª© ‚Üí performance th·∫≠t\n",
    "- Trong production, lu√¥n d·ª± ƒëo√°n t∆∞∆°ng lai t·ª´ qu√° kh·ª© ‚Üí c·∫ßn train/test gi·ªëng v·∫≠y\n",
    "\n",
    "‚Üí **LU√îN d√πng temporal split cho time series!**\n",
    "\n",
    "### 3. RMSE vs MAE?\n",
    "‚úÖ **S·ª± kh√°c bi·ªát:**\n",
    "- MAE: trung b√¨nh sai s·ªë, ƒë·ªëi x·ª≠ b√¨nh ƒë·∫≥ng\n",
    "- RMSE: ph·∫°t n·∫∑ng sai s·ªë l·ªõn (do b√¨nh ph∆∞∆°ng)\n",
    "- RMSE >> MAE ‚Üí c√≥ spike/outlier, model d·ª± b√°o sai m·∫°nh ·ªü v√†i ƒëi·ªÉm\n",
    "\n",
    "‚Üí **N√™n b√°o c√°o C·∫¢ HAI metrics ƒë·ªÉ hi·ªÉu ƒë·∫ßy ƒë·ªß performance!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
