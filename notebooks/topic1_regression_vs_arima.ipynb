{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a3e197a",
   "metadata": {},
   "source": [
    "# Ch·ªß ƒë·ªÅ 1: Regression vs ARIMA ‚Äì Khi n√†o ch·ªçn c√°i n√†o?\n",
    "\n",
    "Notebook n√†y so s√°nh **c√¥ng b·∫±ng** gi·ªØa hai ph∆∞∆°ng ph√°p d·ª± b√°o PM2.5:\n",
    "1. **Baseline Regression** - D·ª± b√°o b·∫±ng lag features v√† time features\n",
    "2. **ARIMA** - M√¥ h√¨nh chu·ªói th·ªùi gian ƒë∆°n bi·∫øn\n",
    "\n",
    "## ƒêi·ªÅu ki·ªán so s√°nh c√¥ng b·∫±ng:\n",
    "- ‚úÖ C√πng tr·∫°m: **Aotizhongxin**\n",
    "- ‚úÖ C√πng CUTOFF: **2017-01-01**\n",
    "- ‚úÖ C√πng HORIZON: **1 gi·ªù**\n",
    "- ‚úÖ C√πng metrics: MAE, RMSE, R¬≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f3e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e249d403",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "RAW_ZIP_PATH = '../data/raw/PRSA2017_Data_20130301-20170228.zip'\n",
    "STATION = 'Aotizhongxin'\n",
    "CUTOFF = '2017-01-01'\n",
    "HORIZON = 1\n",
    "LAG_HOURS = [1, 3, 24]\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "if str(Path('..').resolve()) not in sys.path:\n",
    "    sys.path.insert(0, str(Path('..').resolve()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d248318",
   "metadata": {},
   "source": [
    "## 1. C·∫•u h√¨nh chung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9abb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"C·∫§U H√åNH SO S√ÅNH\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Tr·∫°m: {STATION}\")\n",
    "print(f\"Train/Test cutoff: {CUTOFF}\")\n",
    "print(f\"Horizon: {HORIZON} gi·ªù\")\n",
    "print(f\"Lag features: {LAG_HOURS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b8de3",
   "metadata": {},
   "source": [
    "## 2. Load v√† Chu·∫©n b·ªã D·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b337718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classification_library import load_beijing_air_quality, clean_air_quality_df\n",
    "\n",
    "# Load data\n",
    "df_raw = load_beijing_air_quality(use_ucimlrepo=False, raw_zip_path=RAW_ZIP_PATH)\n",
    "df = clean_air_quality_df(df_raw)\n",
    "\n",
    "# Filter station\n",
    "df_station = df[df['station'] == STATION].sort_values('datetime').reset_index(drop=True)\n",
    "print(f\"Data shape: {df_station.shape}\")\n",
    "print(f\"Date range: {df_station['datetime'].min()} to {df_station['datetime'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee8a81",
   "metadata": {},
   "source": [
    "## 3. M√¥ h√¨nh 1: Baseline Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o features cho regression\n",
    "df_reg = df_station[['datetime', 'PM2.5', 'TEMP', 'PRES', 'DEWP', 'WSPM']].copy()\n",
    "\n",
    "# Lag features\n",
    "for lag in LAG_HOURS:\n",
    "    df_reg[f'PM25_lag{lag}'] = df_reg['PM2.5'].shift(lag)\n",
    "\n",
    "# Time features\n",
    "df_reg['hour'] = df_reg['datetime'].dt.hour\n",
    "df_reg['dayofweek'] = df_reg['datetime'].dt.dayofweek\n",
    "df_reg['month'] = df_reg['datetime'].dt.month\n",
    "\n",
    "# Target: PM2.5 sau HORIZON gi·ªù\n",
    "df_reg['target'] = df_reg['PM2.5'].shift(-HORIZON)\n",
    "\n",
    "# Drop missing\n",
    "df_reg = df_reg.dropna()\n",
    "\n",
    "print(f\"Regression data shape: {df_reg.shape}\")\n",
    "df_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a91b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test theo cutoff\n",
    "cutoff_date = pd.Timestamp(CUTOFF)\n",
    "train_mask = df_reg['datetime'] < cutoff_date\n",
    "test_mask = df_reg['datetime'] >= cutoff_date\n",
    "\n",
    "feature_cols = [col for col in df_reg.columns if col not in ['datetime', 'PM2.5', 'target']]\n",
    "\n",
    "X_train_reg = df_reg.loc[train_mask, feature_cols]\n",
    "y_train_reg = df_reg.loc[train_mask, 'target']\n",
    "X_test_reg = df_reg.loc[test_mask, feature_cols]\n",
    "y_test_reg = df_reg.loc[test_mask, 'target']\n",
    "test_dates_reg = df_reg.loc[test_mask, 'datetime']\n",
    "\n",
    "print(f\"Train: {len(X_train_reg)} samples\")\n",
    "print(f\"Test:  {len(X_test_reg)} samples\")\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3fe284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train regression model\n",
    "print(\"Training Random Forest Regressor...\")\n",
    "model_reg = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "model_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predictions\n",
    "y_pred_reg = model_reg.predict(X_test_reg)\n",
    "\n",
    "# Metrics\n",
    "rmse_reg = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
    "mae_reg = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2_reg = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"REGRESSION MODEL PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"RMSE: {rmse_reg:.2f}\")\n",
    "print(f\"MAE:  {mae_reg:.2f}\")\n",
    "print(f\"R¬≤:   {r2_reg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562abe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model_reg.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTOP 10 IMPORTANT FEATURES:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "feature_importance.head(10).plot(x='feature', y='importance', kind='barh', ax=ax, color='steelblue')\n",
    "ax.set_xlabel('Importance', fontsize=11)\n",
    "ax.set_title('Top 10 Feature Importance - Regression Model', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a19c4",
   "metadata": {},
   "source": [
    "## 4. M√¥ h√¨nh 2: ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4656a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chu·∫©n b·ªã data cho ARIMA\n",
    "df_arima = df_station[['datetime', 'PM2.5']].dropna().copy()\n",
    "df_arima = df_arima.set_index('datetime')\n",
    "\n",
    "# Split train/test\n",
    "train_arima = df_arima[df_arima.index < CUTOFF]['PM2.5']\n",
    "test_arima = df_arima[df_arima.index >= CUTOFF]['PM2.5']\n",
    "\n",
    "print(f\"Train: {len(train_arima)} samples\")\n",
    "print(f\"Test:  {len(test_arima)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a7db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search ARIMA (simplified)\n",
    "print(\"Grid searching ARIMA parameters...\")\n",
    "best_aic = np.inf\n",
    "best_order = None\n",
    "\n",
    "p_range = range(0, 4)\n",
    "d_range = [1]  # Th∆∞·ªùng d=1 cho PM2.5\n",
    "q_range = range(0, 4)\n",
    "\n",
    "results_arima = []\n",
    "for p in p_range:\n",
    "    for d in d_range:\n",
    "        for q in q_range:\n",
    "            try:\n",
    "                model = ARIMA(train_arima, order=(p, d, q))\n",
    "                fitted = model.fit()\n",
    "                if fitted.aic < best_aic:\n",
    "                    best_aic = fitted.aic\n",
    "                    best_order = (p, d, q)\n",
    "                results_arima.append({'p': p, 'd': d, 'q': q, 'aic': fitted.aic})\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "print(f\"\\nBest ARIMA order: {best_order}\")\n",
    "print(f\"Best AIC: {best_aic:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd4702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best ARIMA model\n",
    "print(f\"\\nTraining ARIMA{best_order}...\")\n",
    "model_arima = ARIMA(train_arima, order=best_order)\n",
    "fitted_arima = model_arima.fit()\n",
    "\n",
    "# Forecast\n",
    "forecast_arima = fitted_arima.forecast(steps=len(test_arima))\n",
    "\n",
    "# Metrics\n",
    "rmse_arima = np.sqrt(mean_squared_error(test_arima, forecast_arima))\n",
    "mae_arima = mean_absolute_error(test_arima, forecast_arima)\n",
    "r2_arima = r2_score(test_arima, forecast_arima)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"ARIMA{best_order} MODEL PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"RMSE: {rmse_arima:.2f}\")\n",
    "print(f\"MAE:  {mae_arima:.2f}\")\n",
    "print(f\"R¬≤:   {r2_arima:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c1b3c8",
   "metadata": {},
   "source": [
    "## 5. So S√°nh T·ªïng Quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17032fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B·∫£ng so s√°nh\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Regression (Random Forest)', f'ARIMA{best_order}'],\n",
    "    'RMSE': [rmse_reg, rmse_arima],\n",
    "    'MAE': [mae_reg, mae_arima],\n",
    "    'R¬≤': [r2_reg, r2_arima],\n",
    "    'RMSE/MAE': [rmse_reg/mae_reg, rmse_arima/mae_arima]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SO S√ÅNH T·ªîNG QUAN\")\n",
    "print(\"=\" * 70)\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "metrics = ['RMSE', 'MAE', 'R¬≤']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx]\n",
    "    comparison.plot(x='Model', y=metric, kind='bar', ax=ax, legend=False, color=['steelblue', 'coral'])\n",
    "    ax.set_title(metric, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel('')\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä NH·∫¨N X√âT NHANH:\")\n",
    "if rmse_reg < rmse_arima:\n",
    "    print(f\"‚úÖ Regression T·ªêT H∆†N v·ªÅ RMSE ({rmse_reg:.2f} < {rmse_arima:.2f})\")\n",
    "else:\n",
    "    print(f\"‚úÖ ARIMA T·ªêT H∆†N v·ªÅ RMSE ({rmse_arima:.2f} < {rmse_reg:.2f})\")\n",
    "\n",
    "if mae_reg < mae_arima:\n",
    "    print(f\"‚úÖ Regression T·ªêT H∆†N v·ªÅ MAE ({mae_reg:.2f} < {mae_arima:.2f})\")\n",
    "else:\n",
    "    print(f\"‚úÖ ARIMA T·ªêT H∆†N v·ªÅ MAE ({mae_arima:.2f} < {mae_reg:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b2fa8b",
   "metadata": {},
   "source": [
    "## C√ÇU 1: M√¥ h√¨nh n√†o t·ªët h∆°n cho horizon=1?\n",
    "\n",
    "### Ph√¢n t√≠ch chi ti·∫øt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"C√ÇU 1: M√î H√åNH N√ÄO T·ªêT H∆†N CHO HORIZON=1?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# So s√°nh chi ti·∫øt\n",
    "print(f\"\\n1. PERFORMANCE METRICS:\")\n",
    "print(f\"   Regression: RMSE={rmse_reg:.2f}, MAE={mae_reg:.2f}, R¬≤={r2_reg:.4f}\")\n",
    "print(f\"   ARIMA:      RMSE={rmse_arima:.2f}, MAE={mae_arima:.2f}, R¬≤={r2_arima:.4f}\")\n",
    "\n",
    "winner = \"Regression\" if rmse_reg < rmse_arima else \"ARIMA\"\n",
    "print(f\"\\n   ‚Üí Winner: {winner} (RMSE th·∫•p h∆°n)\")\n",
    "\n",
    "# Ph√¢n t√≠ch feature importance c·ªßa regression\n",
    "top_feature = feature_importance.iloc[0]\n",
    "print(f\"\\n2. FEATURE QUAN TR·ªåNG NH·∫§T (Regression):\")\n",
    "print(f\"   {top_feature['feature']}: {top_feature['importance']:.4f}\")\n",
    "\n",
    "if 'PM25_lag1' in top_feature['feature']:\n",
    "    print(\"   ‚Üí Lag 1h l√† feature quan tr·ªçng nh·∫•t!\")\n",
    "    print(\"   ‚Üí ƒê√∫ng v·ªõi l√Ω thuy·∫øt: d·ª± b√°o ng·∫Øn h·∫°n ph·ª• thu·ªôc m·∫°nh v√†o gi√° tr·ªã g·∫ßn nh·∫•t\")\n",
    "\n",
    "print(f\"\\n3. V√å SAO {winner} T·ªêT H∆†N?\")\n",
    "if winner == \"Regression\":\n",
    "    print(\"   ‚úÖ Regression c√≥ l·ª£i th·∫ø v·ªõi horizon=1 v√¨:\")\n",
    "    print(\"      ‚Ä¢ C√≥ th·ªÉ d√πng tr·ª±c ti·∫øp PM25_lag1 (r·∫•t t∆∞∆°ng quan v·ªõi target)\")\n",
    "    print(\"      ‚Ä¢ C√≥ th·ªÉ k·∫øt h·ª£p nhi·ªÅu features: lag + time + weather\")\n",
    "    print(\"      ‚Ä¢ Random Forest capture ƒë∆∞·ª£c non-linear relationships\")\n",
    "    print(\"      ‚Ä¢ Kh√¥ng y√™u c·∫ßu chu·ªói d·ª´ng hay sai ph√¢n\")\n",
    "else:\n",
    "    print(\"   ‚úÖ ARIMA t·ªët h∆°n v√¨:\")\n",
    "    print(\"      ‚Ä¢ B·∫Øt ƒë∆∞·ª£c c·∫•u tr√∫c t·ª± t∆∞∆°ng quan ph·ª©c t·∫°p qua (p,d,q)\")\n",
    "    print(\"      ‚Ä¢ M√¥ h√¨nh h√≥a tr·ª±c ti·∫øp dynamic c·ªßa time series\")\n",
    "    print(\"      ‚Ä¢ √çt b·ªã overfit h∆°n v·ªõi d·ªØ li·ªáu ·ªìn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e31a8",
   "metadata": {},
   "source": [
    "## C√ÇU 2: M√¥ h√¨nh n√†o ·ªïn h∆°n khi c√≥ spike?\n",
    "\n",
    "### T√¨m v√† ph√¢n t√≠ch ƒëo·∫°n c√≥ spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e26f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√¨m spike trong test set (top 5% gi√° tr·ªã cao nh·∫•t)\n",
    "threshold_spike = test_arima.quantile(0.95)\n",
    "spike_dates = test_arima[test_arima > threshold_spike].index\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"C√ÇU 2: M√î H√åNH N√ÄO ·ªîN H∆†N KHI C√ì SPIKE?\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nThreshold spike (95th percentile): {threshold_spike:.2f}\")\n",
    "print(f\"S·ªë ƒëi·ªÉm spike trong test: {len(spike_dates)}\")\n",
    "\n",
    "if len(spike_dates) > 0:\n",
    "    # Ch·ªçn m·ªôt spike ƒë·ªÉ ph√¢n t√≠ch (spike ƒë·∫ßu ti√™n)\n",
    "    spike_start = spike_dates[0] - pd.Timedelta(days=1)\n",
    "    spike_end = spike_dates[0] + pd.Timedelta(days=2)\n",
    "    \n",
    "    print(f\"\\nPh√¢n t√≠ch spike t·∫°i: {spike_dates[0]}\")\n",
    "    print(f\"Zoom v√†o kho·∫£ng: {spike_start} ƒë·∫øn {spike_end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79efb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize spike region\n",
    "if len(spike_dates) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Filter data in spike region\n",
    "    mask_spike = (test_arima.index >= spike_start) & (test_arima.index <= spike_end)\n",
    "    actual_spike = test_arima[mask_spike]\n",
    "    forecast_arima_spike = forecast_arima[mask_spike]\n",
    "    \n",
    "    # Get regression predictions for same period\n",
    "    mask_reg_spike = (test_dates_reg >= spike_start) & (test_dates_reg <= spike_end)\n",
    "    reg_spike_dates = test_dates_reg[mask_reg_spike]\n",
    "    reg_spike_actual = y_test_reg[mask_reg_spike]\n",
    "    reg_spike_pred = y_pred_reg[mask_reg_spike.values]\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(actual_spike.index, actual_spike.values, 'o-', linewidth=2, markersize=4, \n",
    "            label='Actual', color='black', alpha=0.8)\n",
    "    ax.plot(forecast_arima_spike.index, forecast_arima_spike.values, 's--', linewidth=2, markersize=3,\n",
    "            label=f'ARIMA{best_order}', color='coral', alpha=0.8)\n",
    "    ax.plot(reg_spike_dates.values, reg_spike_pred, '^--', linewidth=2, markersize=3,\n",
    "            label='Regression', color='steelblue', alpha=0.8)\n",
    "    \n",
    "    ax.axhline(y=threshold_spike, color='red', linestyle=':', linewidth=2, \n",
    "               label=f'Spike threshold ({threshold_spike:.0f})')\n",
    "    \n",
    "    ax.set_xlabel('Time', fontsize=11)\n",
    "    ax.set_ylabel('PM2.5 (Œºg/m¬≥)', fontsize=11)\n",
    "    ax.set_title('Forecast vs Actual - V√πng c√≥ SPIKE', fontsize=13, fontweight='bold')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate errors for spike region\n",
    "    mae_arima_spike = mean_absolute_error(actual_spike, forecast_arima_spike)\n",
    "    rmse_arima_spike = np.sqrt(mean_squared_error(actual_spike, forecast_arima_spike))\n",
    "    \n",
    "    mae_reg_spike = mean_absolute_error(reg_spike_actual, reg_spike_pred)\n",
    "    rmse_reg_spike = np.sqrt(mean_squared_error(reg_spike_actual, reg_spike_pred))\n",
    "    \n",
    "    print(\"\\nPERFORMANCE TR√äN V√ôNG SPIKE:\")\n",
    "    print(f\"ARIMA:      MAE={mae_arima_spike:.2f}, RMSE={rmse_arima_spike:.2f}, RMSE/MAE={rmse_arima_spike/mae_arima_spike:.3f}\")\n",
    "    print(f\"Regression: MAE={mae_reg_spike:.2f}, RMSE={rmse_reg_spike:.2f}, RMSE/MAE={rmse_reg_spike/mae_reg_spike:.3f}\")\n",
    "    \n",
    "    print(\"\\nüìä PH√ÇN T√çCH:\")\n",
    "    if rmse_arima_spike/mae_arima_spike > rmse_reg_spike/mae_reg_spike:\n",
    "        print(\"‚ùå ARIMA c√≥ RMSE/MAE ratio cao h∆°n ‚Üí b·ªã ph·∫°t n·∫∑ng h∆°n ·ªü spike\")\n",
    "        print(\"   ‚Üí ARIMA c√≥ xu h∆∞·ªõng m∆∞·ª£t h√≥a (smoothing), kh√¥ng ph·∫£n ·ª©ng nhanh v·ªõi spike\")\n",
    "    else:\n",
    "        print(\"‚ùå Regression c√≥ RMSE/MAE ratio cao h∆°n ‚Üí b·ªã ph·∫°t n·∫∑ng h∆°n ·ªü spike\")\n",
    "        print(\"   ‚Üí Regression c√≥ th·ªÉ overreact ho·∫∑c underpredict spike\")\n",
    "    \n",
    "    if mae_reg_spike < mae_arima_spike:\n",
    "        print(f\"\\n‚úÖ Regression ·ªîN H∆†N v·ªõi spike (MAE th·∫•p h∆°n)\")\n",
    "        print(\"   ‚Üí Nh·ªù c√≥ lag features g·∫ßn (PM25_lag1) ƒë·ªÉ b√°m theo spike\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ ARIMA ·ªîN H∆†N v·ªõi spike (MAE th·∫•p h∆°n)\")\n",
    "        print(\"   ‚Üí ARIMA capture ƒë∆∞·ª£c pattern bi·∫øn ƒë·ªông t·ªët h∆°n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9f69f0",
   "metadata": {},
   "source": [
    "## C√ÇU 3: N·∫øu tri·ªÉn khai th·∫≠t, b·∫°n ch·ªçn g√¨ v√† v√¨ sao?\n",
    "\n",
    "### Ph√¢n t√≠ch ƒëa chi·ªÅu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"C√ÇU 3: N·∫æU TRI·ªÇN KHAI TH·∫¨T, CH·ªåN G√å V√Ä V√å SAO?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìã B·∫¢NG PH√ÇN T√çCH ƒêA CHI·ªÄU:\")\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(f\"{'Ti√™u ch√≠':<30} {'Regression':<20} {'ARIMA':<20}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'1. Accuracy (RMSE)':<30} {rmse_reg::<20.2f} {rmse_arima::<20.2f}\")\n",
    "print(f\"{'2. Stability (MAE)':<30} {mae_reg::<20.2f} {mae_arima::<20.2f}\")\n",
    "print(f\"{'3. Spike handling':<30} {'T·ªët (lag features)':<20} {'Smoothing':<20}\")\n",
    "print(f\"{'4. Interpretability':<30} {'Feature importance':<20} {'(p,d,q) + CI':<20}\")\n",
    "print(f\"{'5. Extensibility':<30} {'D·ªÖ th√™m features':<20} {'Kh√≥ (univariate)':<20}\")\n",
    "print(f\"{'6. Training time':<30} {'Trung b√¨nh':<20} {'Ch·∫≠m (grid search)':<20}\")\n",
    "print(f\"{'7. Prediction time':<30} {'Nhanh':<20} {'Nhanh':<20}\")\n",
    "print(f\"{'8. Update frequency':<30} {'D·ªÖ (retrain)':<20} {'Kh√≥ (re-fit)':<20}\")\n",
    "print(f\"{'9. Confidence interval':<30} {'Kh√¥ng c√≥ s·∫µn':<20} {'C√≥ s·∫µn':<20}\")\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1174b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüí° KHUY·∫æN NGH·ªä THEO B·ªêI C·∫¢NH:\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "print(\"\\nüéØ B·ªêI C·∫¢NH 1: H·ªÜ TH·ªêNG C·∫¢NH B√ÅO S·ªöM\")\n",
    "print(\"-\" * 70)\n",
    "print(\"M·ª•c ti√™u: D·ª± b√°o CH√çNH X√ÅC ƒë·ªÉ k√≠ch ho·∫°t c·∫£nh b√°o k·ªãp th·ªùi\")\n",
    "print(\"\\n‚Üí CH·ªåN: REGRESSION\")\n",
    "print(\"   L√Ω do:\")\n",
    "print(\"   ‚úÖ RMSE/MAE th·∫•p h∆°n ‚Üí √≠t false alarm\")\n",
    "print(\"   ‚úÖ C√≥ th·ªÉ th√™m weather forecast l√†m features\")\n",
    "print(\"   ‚úÖ Ph·∫£n ·ª©ng nhanh v·ªõi spike (nh·ªù lag1)\")\n",
    "print(\"   ‚úÖ D·ªÖ update model khi c√≥ data m·ªõi\")\n",
    "\n",
    "print(\"\\nüéØ B·ªêI C·∫¢NH 2: NGHI√äN C·ª®U & PH√ÇN T√çCH XU H∆Ø·ªöNG\")\n",
    "print(\"-\" * 70)\n",
    "print(\"M·ª•c ti√™u: Hi·ªÉu C·∫§U TR√öC v√† XU H∆Ø·ªöNG d√†i h·∫°n\")\n",
    "print(\"\\n‚Üí CH·ªåN: ARIMA\")\n",
    "print(\"   L√Ω do:\")\n",
    "print(\"   ‚úÖ (p,d,q) gi·∫£i th√≠ch ƒë∆∞·ª£c c·∫•u tr√∫c time series\")\n",
    "print(\"   ‚úÖ C√≥ confidence interval cho uncertainty\")\n",
    "print(\"   ‚úÖ Ph√π h·ª£p v·ªõi forecasting d√†i h·∫°n (multi-step)\")\n",
    "print(\"   ‚úÖ Chu·∫©n m·ª±c trong econometrics/environmental science\")\n",
    "\n",
    "print(\"\\nüéØ B·ªêI C·∫¢NH 3: PRODUCTION SYSTEM (REAL-TIME)\")\n",
    "print(\"-\" * 70)\n",
    "print(\"M·ª•c ti√™u: D·ª± b√°o 24/7 v·ªõi ƒë·ªô tin c·∫≠y cao, d·ªÖ maintain\")\n",
    "print(\"\\n‚Üí CH·ªåN: REGRESSION (ho·∫∑c HYBRID)\")\n",
    "print(\"   L√Ω do:\")\n",
    "print(\"   ‚úÖ Prediction speed nhanh\")\n",
    "print(\"   ‚úÖ D·ªÖ monitor (feature drift, model drift)\")\n",
    "print(\"   ‚úÖ D·ªÖ A/B testing v·ªõi models kh√°c\")\n",
    "print(\"   ‚úÖ C√≥ th·ªÉ ensemble v·ªõi ARIMA n·∫øu c·∫ßn\")\n",
    "\n",
    "print(\"\\nüéØ B·ªêI C·∫¢NH 4: B√ÅO C√ÅO CH√çNH PH·ª¶ / CH√çNH S√ÅCH\")\n",
    "print(\"-\" * 70)\n",
    "print(\"M·ª•c ti√™u: DI·ªÑN GI·∫¢I ƒë∆∞·ª£c cho policy makers\")\n",
    "print(\"\\n‚Üí CH·ªåN: ARIMA (ho·∫∑c c·∫£ hai)\")\n",
    "print(\"   L√Ω do:\")\n",
    "print(\"   ‚úÖ M√¥ h√¨nh th·ªëng k√™ truy·ªÅn th·ªëng, d·ªÖ ch·∫•p nh·∫≠n\")\n",
    "print(\"   ‚úÖ Confidence interval quan tr·ªçng cho risk assessment\")\n",
    "print(\"   ‚úÖ C√≥ th·ªÉ gi·∫£i th√≠ch 't√≠nh d·ª´ng', 'xu h∆∞·ªõng', 'm√πa v·ª•'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dddea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìå K·∫æT LU·∫¨N CU·ªêI C√ôNG\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if rmse_reg < rmse_arima:\n",
    "    print(\"\\n‚úÖ KHUY·∫æN NGH·ªä: REGRESSION (Random Forest)\")\n",
    "    print(\"\\nL√Ω do ch√≠nh:\")\n",
    "    print(f\"  1. Performance t·ªët h∆°n: RMSE={rmse_reg:.2f} < {rmse_arima:.2f}\")\n",
    "    print(f\"  2. Ph√π h·ª£p v·ªõi horizon=1 (short-term forecast)\")\n",
    "    print(f\"  3. D·ªÖ m·ªü r·ªông: c√≥ th·ªÉ th√™m weather forecast, traffic, etc.\")\n",
    "    print(f\"  4. D·ªÖ deploy v√† maintain trong production\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ KHUY·∫æN NGH·ªä: ARIMA\")\n",
    "    print(\"\\nL√Ω do ch√≠nh:\")\n",
    "    print(f\"  1. Performance t·ªët h∆°n: RMSE={rmse_arima:.2f} < {rmse_reg:.2f}\")\n",
    "    print(f\"  2. M√¥ h√¨nh h√≥a tr·ª±c ti·∫øp time series structure\")\n",
    "    print(f\"  3. C√≥ confidence interval cho uncertainty quantification\")\n",
    "    print(f\"  4. Ph√π h·ª£p v·ªõi forecasting nhi·ªÅu b∆∞·ªõc\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è L∆ØU √ù:\")\n",
    "print(\"  ‚Ä¢ N√™n d√πng ENSEMBLE (k·∫øt h·ª£p c·∫£ hai) n·∫øu c√≥ t√†i nguy√™n\")\n",
    "print(\"  ‚Ä¢ Monitor performance li√™n t·ª•c, retrain ƒë·ªãnh k·ª≥\")\n",
    "print(\"  ‚Ä¢ Th√™m external features (weather, traffic) ƒë·ªÉ c·∫£i thi·ªán\")\n",
    "print(\"  ‚Ä¢ Xem x√©t deep learning (LSTM, Transformer) cho b√†i to√°n ph·ª©c t·∫°p h∆°n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9deb49",
   "metadata": {},
   "source": [
    "## T√ìM T·∫ÆT 3 C√ÇU H·ªéI\n",
    "\n",
    "### C√ÇU 1: M√¥ h√¨nh n√†o t·ªët h∆°n cho horizon=1?\n",
    "**K·∫øt lu·∫≠n:** Th∆∞·ªùng l√† **Regression** v√¨:\n",
    "- C√≥ th·ªÉ d√πng tr·ª±c ti·∫øp lag features (ƒë·∫∑c bi·ªát lag1 r·∫•t quan tr·ªçng)\n",
    "- K·∫øt h·ª£p ƒë∆∞·ª£c nhi·ªÅu ngu·ªìn th√¥ng tin (lag + time + weather)\n",
    "- D·ª± b√°o ng·∫Øn h·∫°n ph·ª• thu·ªôc m·∫°nh v√†o gi√° tr·ªã g·∫ßn nh·∫•t\n",
    "\n",
    "### C√ÇU 2: M√¥ h√¨nh n√†o ·ªïn h∆°n khi c√≥ spike?\n",
    "**K·∫øt lu·∫≠n:** Ph·ª• thu·ªôc v√†o:\n",
    "- **Regression** th∆∞·ªùng ph·∫£n ·ª©ng nhanh h∆°n (nh·ªù lag1)\n",
    "- **ARIMA** c√≥ xu h∆∞·ªõng smoothing, ch·∫≠m ph·∫£n ·ª©ng\n",
    "- Xem RMSE/MAE ratio: cao ‚Üí b·ªã ph·∫°t n·∫∑ng ·ªü spike\n",
    "\n",
    "### C√ÇU 3: Tri·ªÉn khai th·∫≠t ch·ªçn g√¨?\n",
    "**K·∫øt lu·∫≠n:** T√πy b·ªëi c·∫£nh:\n",
    "- **C·∫£nh b√°o s·ªõm** ‚Üí Regression (ch√≠nh x√°c, d·ªÖ update)\n",
    "- **Nghi√™n c·ª©u** ‚Üí ARIMA (gi·∫£i th√≠ch, CI)\n",
    "- **Production** ‚Üí Regression ho·∫∑c Hybrid\n",
    "- **B√°o c√°o ch√≠nh ph·ªß** ‚Üí ARIMA (chu·∫©n m·ª±c)\n",
    "\n",
    "**Best practice:** Ensemble c·∫£ hai n·∫øu c√≥ t√†i nguy√™n!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}