{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0cfd76",
   "metadata": {},
   "source": [
    "# Q3: ARIMA - Quy Tr√¨nh Ra Quy·∫øt ƒê·ªãnh\n",
    "\n",
    "Notebook n√†y gi·∫£i th√≠ch **quy tr√¨nh ho√†n ch·ªânh** ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh ARIMA cho d·ª± b√°o PM2.5:\n",
    "\n",
    "1. **Quan s√°t chu·ªói g·ªëc** - Nh·∫≠n di·ªán xu h∆∞·ªõng v√† m√πa v·ª•\n",
    "2. **Ki·ªÉm ƒë·ªãnh d·ª´ng** (ADF/KPSS) - Ch·ªçn d\n",
    "3. **Xem ACF/PACF** - ƒêo√°n p v√† q\n",
    "4. **Grid search** - T√¨m (p,d,q) t·ªëi ∆∞u\n",
    "5. **Ch·∫©n ƒëo√°n ph·∫ßn d∆∞** - Ki·ªÉm tra residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24932b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65361b18",
   "metadata": {},
   "source": [
    "## Load v√† Chu·∫©n b·ªã D·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428be8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classification_library import load_beijing_air_quality, clean_air_quality_df\n",
    "\n",
    "RAW_ZIP_PATH = '../data/raw/PRSA2017_Data_20130301-20170228.zip'\n",
    "STATION = 'Aotizhongxin'\n",
    "VALUE_COL = 'PM2.5'\n",
    "CUTOFF = '2017-01-01'\n",
    "\n",
    "# Load data\n",
    "df_raw = load_beijing_air_quality(use_ucimlrepo=False, raw_zip_path=RAW_ZIP_PATH)\n",
    "df = clean_air_quality_df(df_raw)\n",
    "\n",
    "# L·ªçc tr·∫°m v√† t·∫°o time series\n",
    "df_station = df[df['station'] == STATION].sort_values('datetime').reset_index(drop=True)\n",
    "df_ts = df_station[['datetime', VALUE_COL]].dropna().copy()\n",
    "df_ts = df_ts.set_index('datetime')\n",
    "\n",
    "print(f\"Time series shape: {df_ts.shape}\")\n",
    "print(f\"Date range: {df_ts.index.min()} to {df_ts.index.max()}\")\n",
    "df_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea33d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "train = df_ts[df_ts.index < CUTOFF]\n",
    "test = df_ts[df_ts.index >= CUTOFF]\n",
    "\n",
    "print(f\"Train: {len(train)} observations ({train.index.min()} to {train.index.max()})\")\n",
    "print(f\"Test:  {len(test)} observations ({test.index.min()} to {test.index.max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ddf48d",
   "metadata": {},
   "source": [
    "## B∆Ø·ªöC 1: Quan s√°t Chu·ªói G·ªëc - Nh·∫≠n di·ªán Xu h∆∞·ªõng v√† M√πa v·ª•\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- Xem chu·ªói c√≥ xu h∆∞·ªõng (trend) kh√¥ng?\n",
    "- C√≥ t√≠nh m√πa v·ª• (seasonality) kh√¥ng?\n",
    "- C√≥ pattern l·∫∑p l·∫°i kh√¥ng?\n",
    "\n",
    "**Ph∆∞∆°ng ph√°p:**\n",
    "- V·∫Ω ƒë·ªì th·ªã to√†n b·ªô chu·ªói\n",
    "- T√≠nh moving average ƒë·ªÉ l√†m m∆∞·ª£t\n",
    "- Decomposition (n·∫øu c·∫ßn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"B∆Ø·ªöC 1: QUAN S√ÅT CHU·ªñI G·ªêC\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Original series\n",
    "ax1 = axes[0]\n",
    "ax1.plot(train.index, train[VALUE_COL], linewidth=0.8, alpha=0.7, color='steelblue')\n",
    "ax1.set_ylabel(VALUE_COL, fontsize=11)\n",
    "ax1.set_title(f'{VALUE_COL} Original Series (Training Data)', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: With moving averages\n",
    "ax2 = axes[1]\n",
    "ax2.plot(train.index, train[VALUE_COL], linewidth=0.5, alpha=0.5, color='lightblue', label='Original')\n",
    "train_copy = train.copy()\n",
    "train_copy['MA_7d'] = train_copy[VALUE_COL].rolling(window=24*7, center=True).mean()\n",
    "train_copy['MA_30d'] = train_copy[VALUE_COL].rolling(window=24*30, center=True).mean()\n",
    "ax2.plot(train_copy.index, train_copy['MA_7d'], linewidth=2, color='orange', label='7-day MA')\n",
    "ax2.plot(train_copy.index, train_copy['MA_30d'], linewidth=2, color='red', label='30-day MA')\n",
    "ax2.set_ylabel(VALUE_COL, fontsize=11)\n",
    "ax2.set_title('V·ªõi Moving Averages (ƒë·ªÉ quan s√°t xu h∆∞·ªõng)', fontsize=13, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Monthly aggregation\n",
    "ax3 = axes[2]\n",
    "monthly_mean = train.resample('ME')[VALUE_COL].mean()\n",
    "ax3.plot(monthly_mean.index, monthly_mean.values, marker='o', linewidth=2, markersize=6, color='green')\n",
    "ax3.set_ylabel(f'Monthly Mean {VALUE_COL}', fontsize=11)\n",
    "ax3.set_xlabel('Time', fontsize=11)\n",
    "ax3.set_title('Trung b√¨nh theo th√°ng (ƒë·ªÉ quan s√°t seasonality)', fontsize=13, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä QUAN S√ÅT:\")\n",
    "print(\"- C√≥ xu h∆∞·ªõng d√†i h·∫°n (tƒÉng/gi·∫£m) kh√¥ng?\")\n",
    "print(\"- C√≥ pattern l·∫∑p l·∫°i theo m√πa kh√¥ng?\")\n",
    "print(\"- Ph∆∞∆°ng sai c√≥ thay ƒë·ªïi theo th·ªùi gian kh√¥ng?\")\n",
    "print(\"\\n‚Üí Quan s√°t n√†y gi√∫p quy·∫øt ƒë·ªãnh c√≥ c·∫ßn differencing v√† seasonality component kh√¥ng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00ea7f7",
   "metadata": {},
   "source": [
    "## B∆Ø·ªöC 2: Ki·ªÉm ƒë·ªãnh D·ª´ng (Stationarity) - Ch·ªçn d\n",
    "\n",
    "**M·ª•c ti√™u:** X√°c ƒë·ªãnh tham s·ªë **d** (order of differencing)\n",
    "\n",
    "**Ph∆∞∆°ng ph√°p:**\n",
    "1. ADF test (Augmented Dickey-Fuller)\n",
    "   - H0: chu·ªói kh√¥ng d·ª´ng (c√≥ unit root)\n",
    "   - p < 0.05 ‚Üí reject H0 ‚Üí chu·ªói d·ª´ng\n",
    "\n",
    "2. KPSS test\n",
    "   - H0: chu·ªói d·ª´ng\n",
    "   - p < 0.05 ‚Üí reject H0 ‚Üí chu·ªói kh√¥ng d·ª´ng\n",
    "\n",
    "**Quy t·∫Øc ch·ªçn d:**\n",
    "- Chu·ªói d·ª´ng ‚Üí d=0\n",
    "- Chu·ªói kh√¥ng d·ª´ng ‚Üí th·ª≠ d=1 (first difference)\n",
    "- N·∫øu v·∫´n ch∆∞a d·ª´ng ‚Üí th·ª≠ d=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7f55e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"B∆Ø·ªöC 2: KI·ªÇM ƒê·ªäNH D·ª™NG - CH·ªåN d\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def test_stationarity(series, series_name=\"Series\"):\n",
    "    \"\"\"Ki·ªÉm ƒë·ªãnh t√≠nh d·ª´ng b·∫±ng ADF v√† KPSS\"\"\"\n",
    "    print(f\"\\n{series_name}:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # ADF Test\n",
    "    adf_result = adfuller(series.dropna(), autolag='AIC')\n",
    "    print(f\"ADF Test:\")\n",
    "    print(f\"  Statistic: {adf_result[0]:.4f}\")\n",
    "    print(f\"  P-value:   {adf_result[1]:.4f}\")\n",
    "    print(f\"  Critical values: {adf_result[4]}\")\n",
    "    \n",
    "    adf_stationary = adf_result[1] < 0.05\n",
    "    print(f\"  ‚Üí {'‚úÖ D·ª™NG' if adf_stationary else '‚ùå KH√îNG D·ª™NG'} (ADF)\")\n",
    "    \n",
    "    # KPSS Test\n",
    "    kpss_result = kpss(series.dropna(), regression='c', nlags='auto')\n",
    "    print(f\"\\nKPSS Test:\")\n",
    "    print(f\"  Statistic: {kpss_result[0]:.4f}\")\n",
    "    print(f\"  P-value:   {kpss_result[1]:.4f}\")\n",
    "    print(f\"  Critical values: {kpss_result[3]}\")\n",
    "    \n",
    "    kpss_stationary = kpss_result[1] >= 0.05\n",
    "    print(f\"  ‚Üí {'‚úÖ D·ª™NG' if kpss_stationary else '‚ùå KH√îNG D·ª™NG'} (KPSS)\")\n",
    "    \n",
    "    # K·∫øt lu·∫≠n\n",
    "    if adf_stationary and kpss_stationary:\n",
    "        conclusion = \"‚úÖ‚úÖ C·∫¢ HAI TEST ƒê·ªíNG √ù: D·ª™NG\"\n",
    "        is_stationary = True\n",
    "    elif not adf_stationary and not kpss_stationary:\n",
    "        conclusion = \"‚ùå‚ùå C·∫¢ HAI TEST ƒê·ªíNG √ù: KH√îNG D·ª™NG\"\n",
    "        is_stationary = False\n",
    "    else:\n",
    "        conclusion = \"‚ö†Ô∏è HAI TEST M√ÇU THU·∫™N - c·∫ßn xem x√©t th√™m\"\n",
    "        is_stationary = False\n",
    "    \n",
    "    print(f\"\\n{conclusion}\")\n",
    "    return is_stationary\n",
    "\n",
    "# Test original series\n",
    "series = train[VALUE_COL]\n",
    "is_stationary_d0 = test_stationarity(series, \"Chu·ªói G·ªêC (d=0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da461d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N·∫øu kh√¥ng d·ª´ng, th·ª≠ differencing\n",
    "if not is_stationary_d0:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"Chu·ªói g·ªëc KH√îNG D·ª™NG ‚Üí Th·ª≠ DIFFERENCING\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # First difference\n",
    "    series_diff1 = series.diff().dropna()\n",
    "    is_stationary_d1 = test_stationarity(series_diff1, \"First Difference (d=1)\")\n",
    "    \n",
    "    if not is_stationary_d1:\n",
    "        # Second difference\n",
    "        series_diff2 = series_diff1.diff().dropna()\n",
    "        is_stationary_d2 = test_stationarity(series_diff2, \"Second Difference (d=2)\")\n",
    "        \n",
    "        if is_stationary_d2:\n",
    "            recommended_d = 2\n",
    "        else:\n",
    "            recommended_d = 1  # fallback\n",
    "    else:\n",
    "        recommended_d = 1\n",
    "else:\n",
    "    recommended_d = 0\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"üìå KHUY·∫æN NGH·ªä: d = {recommended_d}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e213538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize differencing effect\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Original\n",
    "axes[0].plot(series.values[:1000], linewidth=1, color='blue')\n",
    "axes[0].set_title('Chu·ªói G·ªëc (d=0)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel(VALUE_COL)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# First difference\n",
    "if recommended_d >= 1:\n",
    "    axes[1].plot(series_diff1.values[:1000], linewidth=1, color='orange')\n",
    "    axes[1].set_title('First Difference (d=1)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Œî ' + VALUE_COL)\n",
    "    axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Second difference\n",
    "if recommended_d >= 2:\n",
    "    axes[2].plot(series_diff2.values[:1000], linewidth=1, color='green')\n",
    "    axes[2].set_title('Second Difference (d=2)', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_ylabel('Œî¬≤ ' + VALUE_COL)\n",
    "    axes[2].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a04cd",
   "metadata": {},
   "source": [
    "## B∆Ø·ªöC 3: Xem ACF/PACF - ƒêo√°n p v√† q\n",
    "\n",
    "**M·ª•c ti√™u:** X√°c ƒë·ªãnh tham s·ªë **p** (AR order) v√† **q** (MA order)\n",
    "\n",
    "**Quy t·∫Øc ƒë∆°n gi·∫£n:**\n",
    "\n",
    "| Pattern | ACF | PACF | Model |\n",
    "|---------|-----|------|-------|\n",
    "| AR(p) | Decay d·∫ßn | Cut off sau lag p | p = s·ªë lag tr∆∞·ªõc khi PACF cut off |\n",
    "| MA(q) | Cut off sau lag q | Decay d·∫ßn | q = s·ªë lag tr∆∞·ªõc khi ACF cut off |\n",
    "| ARMA(p,q) | Decay d·∫ßn | Decay d·∫ßn | C·∫ßn th·ª≠ nhi·ªÅu gi√° tr·ªã |\n",
    "\n",
    "**Th·ª±c t·∫ø:**\n",
    "- Th∆∞·ªùng kh√≥ x√°c ƒë·ªãnh ch√≠nh x√°c t·ª´ ACF/PACF\n",
    "- D√πng ACF/PACF ƒë·ªÉ g·ª£i √Ω kho·∫£ng gi√° tr·ªã (v√≠ d·ª•: p ‚â§ 3, q ‚â§ 3)\n",
    "- Sau ƒë√≥ d√πng grid search ƒë·ªÉ t√¨m gi√° tr·ªã t·ªëi ∆∞u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6fd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"B∆Ø·ªöC 3: XEM ACF/PACF - ƒêO√ÅN p v√† q\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Ch·ªçn chu·ªói ph√π h·ª£p (sau differencing n·∫øu c·∫ßn)\n",
    "if recommended_d == 0:\n",
    "    series_for_acf = series\n",
    "elif recommended_d == 1:\n",
    "    series_for_acf = series_diff1\n",
    "else:\n",
    "    series_for_acf = series_diff2\n",
    "\n",
    "# Plot ACF and PACF\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# ACF\n",
    "plot_acf(series_for_acf.dropna(), lags=40, ax=axes[0])\n",
    "axes[0].set_title(f'ACF - Autocorrelation Function (d={recommended_d})', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Lag', fontsize=11)\n",
    "\n",
    "# PACF\n",
    "plot_pacf(series_for_acf.dropna(), lags=40, ax=axes[1])\n",
    "axes[1].set_title(f'PACF - Partial Autocorrelation Function (d={recommended_d})', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Lag', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä H∆Ø·ªöNG D·∫™N ƒê·ªåC:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"ACF (Autocorrelation):\")\n",
    "print(\"  - N·∫øu cut off ƒë·ªôt ng·ªôt sau lag q ‚Üí model c√≥ th√†nh ph·∫ßn MA(q)\")\n",
    "print(\"  - N·∫øu decay d·∫ßn ‚Üí model c√≥ th√†nh ph·∫ßn AR\")\n",
    "print(\"\\nPACF (Partial Autocorrelation):\")\n",
    "print(\"  - N·∫øu cut off ƒë·ªôt ng·ªôt sau lag p ‚Üí model c√≥ th√†nh ph·∫ßn AR(p)\")\n",
    "print(\"  - N·∫øu decay d·∫ßn ‚Üí model c√≥ th√†nh ph·∫ßn MA\")\n",
    "print(\"\\n‚ö†Ô∏è Trong th·ª±c t·∫ø, pattern th∆∞·ªùng kh√¥ng r√µ r√†ng nh∆∞ s√°ch v·ªü\")\n",
    "print(\"‚Üí D√πng ACF/PACF ƒë·ªÉ g·ª£i √Ω kho·∫£ng gi√° tr·ªã, sau ƒë√≥ d√πng grid search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G·ª£i √Ω p v√† q t·ª´ ACF/PACF\n",
    "acf_values = acf(series_for_acf.dropna(), nlags=20)\n",
    "pacf_values = pacf(series_for_acf.dropna(), nlags=20)\n",
    "\n",
    "# T√¨m lag ƒë·∫ßu ti√™n m√† ACF/PACF kh√¥ng significant (trong CI)\n",
    "# CI ‚âà ¬±1.96/sqrt(n) for 95% confidence\n",
    "n = len(series_for_acf.dropna())\n",
    "ci = 1.96 / np.sqrt(n)\n",
    "\n",
    "# T√¨m q candidate (t·ª´ ACF)\n",
    "q_candidates = []\n",
    "for i in range(1, len(acf_values)):\n",
    "    if abs(acf_values[i]) > ci:\n",
    "        q_candidates.append(i)\n",
    "    elif len(q_candidates) > 0:\n",
    "        break  # stop at first insignificant lag after significant ones\n",
    "\n",
    "# T√¨m p candidate (t·ª´ PACF)\n",
    "p_candidates = []\n",
    "for i in range(1, len(pacf_values)):\n",
    "    if abs(pacf_values[i]) > ci:\n",
    "        p_candidates.append(i)\n",
    "    elif len(p_candidates) > 0:\n",
    "        break\n",
    "\n",
    "suggested_p_max = max(p_candidates) if p_candidates else 1\n",
    "suggested_q_max = max(q_candidates) if q_candidates else 1\n",
    "\n",
    "# Gi·ªõi h·∫°n ƒë·ªÉ tr√°nh qu√° ph·ª©c t·∫°p\n",
    "suggested_p_max = min(suggested_p_max, 5)\n",
    "suggested_q_max = min(suggested_q_max, 5)\n",
    "\n",
    "print(\"\\nüìå G·ª¢I √ù T·ª™ ACF/PACF:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"p (AR order):  th·ª≠ t·ª´ 0 ƒë·∫øn {suggested_p_max}\")\n",
    "print(f\"q (MA order):  th·ª≠ t·ª´ 0 ƒë·∫øn {suggested_q_max}\")\n",
    "print(f\"d (differencing): {recommended_d}\")\n",
    "print(\"\\n‚Üí S·∫Ω d√πng grid search ƒë·ªÉ t√¨m (p,d,q) t·ªëi ∆∞u trong kho·∫£ng n√†y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be7fe2f",
   "metadata": {},
   "source": [
    "## B∆Ø·ªöC 4: Grid Search - T√¨m (p,d,q) t·ªëi ∆∞u\n",
    "\n",
    "**M·ª•c ti√™u:** T√¨m t·ªï h·ª£p (p,d,q) cho AIC/BIC th·∫•p nh·∫•t\n",
    "\n",
    "**AIC vs BIC:**\n",
    "- AIC (Akaike Information Criterion): c√¢n b·∫±ng gi·ªØa goodness-of-fit v√† ƒë·ªô ph·ª©c t·∫°p\n",
    "- BIC (Bayesian Information Criterion): ph·∫°t m√¥ h√¨nh ph·ª©c t·∫°p n·∫∑ng h∆°n AIC\n",
    "- Th∆∞·ªùng d√πng AIC cho forecasting, BIC cho model selection\n",
    "\n",
    "**Quy t·∫Øc:**\n",
    "- C√†ng th·∫•p c√†ng t·ªët\n",
    "- ∆Øu ti√™n model ƒë∆°n gi·∫£n n·∫øu AIC/BIC g·∫ßn nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2636a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"B∆Ø·ªöC 4: GRID SEARCH - T√åM (p,d,q) T·ªêI ∆ØU\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Grid search\n",
    "p_range = range(0, suggested_p_max + 1)\n",
    "d_range = [recommended_d]  # Gi·ªØ d c·ªë ƒë·ªãnh\n",
    "q_range = range(0, suggested_q_max + 1)\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"\\nTh·ª≠ {len(p_range)} x {len(d_range)} x {len(q_range)} = {len(p_range)*len(d_range)*len(q_range)} models...\")\n",
    "print(\"(C√≥ th·ªÉ m·∫•t v√†i ph√∫t)\\n\")\n",
    "\n",
    "for p in p_range:\n",
    "    for d in d_range:\n",
    "        for q in q_range:\n",
    "            try:\n",
    "                model = ARIMA(train[VALUE_COL], order=(p, d, q))\n",
    "                fitted = model.fit()\n",
    "                results.append({\n",
    "                    'p': p, 'd': d, 'q': q,\n",
    "                    'aic': fitted.aic,\n",
    "                    'bic': fitted.bic,\n",
    "                    'order': (p, d, q)\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Top 10 by AIC\n",
    "print(\"\\nTOP 10 MODELS BY AIC:\")\n",
    "print(\"=\" * 70)\n",
    "top_aic = results_df.nsmallest(10, 'aic')\n",
    "print(top_aic.to_string(index=False))\n",
    "\n",
    "# Best model\n",
    "best_by_aic = results_df.loc[results_df['aic'].idxmin()]\n",
    "best_order_aic = (int(best_by_aic['p']), int(best_by_aic['d']), int(best_by_aic['q']))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"üìå BEST MODEL BY AIC: ARIMA{best_order_aic}\")\n",
    "print(f\"   AIC = {best_by_aic['aic']:.2f}\")\n",
    "print(f\"   BIC = {best_by_aic['bic']:.2f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results\n",
    "if len(results_df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Heatmap for AIC\n",
    "    pivot_aic = results_df.pivot_table(values='aic', index='p', columns='q', aggfunc='min')\n",
    "    sns.heatmap(pivot_aic, annot=True, fmt='.0f', cmap='YlOrRd', ax=axes[0])\n",
    "    axes[0].set_title(f'AIC Heatmap (d={recommended_d})', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('q (MA order)')\n",
    "    axes[0].set_ylabel('p (AR order)')\n",
    "    \n",
    "    # Heatmap for BIC\n",
    "    pivot_bic = results_df.pivot_table(values='bic', index='p', columns='q', aggfunc='min')\n",
    "    sns.heatmap(pivot_bic, annot=True, fmt='.0f', cmap='YlGnBu', ax=axes[1])\n",
    "    axes[1].set_title(f'BIC Heatmap (d={recommended_d})', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('q (MA order)')\n",
    "    axes[1].set_ylabel('p (AR order)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377fc7cb",
   "metadata": {},
   "source": [
    "## B∆Ø·ªöC 5: Ch·∫©n ƒëo√°n Ph·∫ßn d∆∞ (Residual Diagnostics)\n",
    "\n",
    "**M·ª•c ti√™u:** Ki·ªÉm tra xem model ƒë√£ b·∫Øt ƒë∆∞·ª£c c·∫•u tr√∫c ch√≠nh c·ªßa chu·ªói ch∆∞a\n",
    "\n",
    "**Ph·∫ßn d∆∞ T·ªêT ph·∫£i:**\n",
    "1. C√≥ mean ‚âà 0\n",
    "2. Ph√¢n ph·ªëi g·∫ßn Normal\n",
    "3. Kh√¥ng c√≥ autocorrelation (‚âà white noise)\n",
    "4. Ph∆∞∆°ng sai ·ªïn ƒë·ªãnh (homoscedastic)\n",
    "\n",
    "**C√°ch ki·ªÉm tra:**\n",
    "- Plot residuals\n",
    "- Histogram & Q-Q plot\n",
    "- ACF of residuals\n",
    "- Ljung-Box test (H0: no autocorrelation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df733eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(f\"B∆Ø·ªöC 5: CH·∫®N ƒêO√ÅN PH·∫¶N D∆Ø - ARIMA{best_order_aic}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Fit best model\n",
    "best_model = ARIMA(train[VALUE_COL], order=best_order_aic)\n",
    "best_fitted = best_model.fit()\n",
    "\n",
    "# Get residuals\n",
    "residuals = best_fitted.resid\n",
    "\n",
    "print(f\"\\nMODEL SUMMARY:\")\n",
    "print(best_fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual diagnostics plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Residuals over time\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(residuals, linewidth=0.8, color='steelblue')\n",
    "ax1.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax1.set_title('Residuals Over Time', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Residuals')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Histogram\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(residuals, bins=50, density=True, alpha=0.7, color='coral', edgecolor='black')\n",
    "# Overlay normal distribution\n",
    "mu, sigma = residuals.mean(), residuals.std()\n",
    "x = np.linspace(residuals.min(), residuals.max(), 100)\n",
    "from scipy.stats import norm\n",
    "ax2.plot(x, norm.pdf(x, mu, sigma), 'r-', linewidth=2, label='Normal fit')\n",
    "ax2.set_title('Residuals Distribution', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Residuals')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Q-Q plot\n",
    "from scipy import stats\n",
    "ax3 = axes[1, 0]\n",
    "stats.probplot(residuals, dist=\"norm\", plot=ax3)\n",
    "ax3.set_title('Q-Q Plot', fontsize=12, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: ACF of residuals\n",
    "ax4 = axes[1, 1]\n",
    "plot_acf(residuals, lags=40, ax=ax4)\n",
    "ax4.set_title('ACF of Residuals', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical tests on residuals\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KI·ªÇM ƒê·ªäNH TH·ªêNG K√ä CHO PH·∫¶N D∆Ø\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Mean test\n",
    "print(f\"\\n1. Mean of residuals: {residuals.mean():.6f}\")\n",
    "if abs(residuals.mean()) < 0.1 * residuals.std():\n",
    "    print(\"   ‚úÖ Mean ‚âà 0 (good)\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Mean kh√°c 0 ƒë√°ng k·ªÉ\")\n",
    "\n",
    "# 2. Normality test (Jarque-Bera)\n",
    "from scipy.stats import jarque_bera\n",
    "jb_stat, jb_pvalue = jarque_bera(residuals)\n",
    "print(f\"\\n2. Jarque-Bera test (normality):\")\n",
    "print(f\"   Statistic: {jb_stat:.4f}\")\n",
    "print(f\"   P-value: {jb_pvalue:.6f}\")\n",
    "if jb_pvalue > 0.05:\n",
    "    print(\"   ‚úÖ Residuals g·∫ßn ph√¢n ph·ªëi Normal (p > 0.05)\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Residuals kh√¥ng ph√¢n ph·ªëi Normal (p < 0.05)\")\n",
    "\n",
    "# 3. Ljung-Box test (autocorrelation)\n",
    "lb_test = acorr_ljungbox(residuals, lags=[10, 20, 30], return_df=True)\n",
    "print(f\"\\n3. Ljung-Box test (no autocorrelation):\")\n",
    "print(lb_test)\n",
    "if (lb_test['lb_pvalue'] > 0.05).all():\n",
    "    print(\"   ‚úÖ Kh√¥ng c√≥ autocorrelation ƒë√°ng k·ªÉ (all p > 0.05)\")\n",
    "    print(\"   ‚Üí Residuals ‚âà white noise (GOOD!)\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è V·∫´n c√≤n autocorrelation (some p < 0.05)\")\n",
    "    print(\"   ‚Üí Model ch∆∞a b·∫Øt h·∫øt c·∫•u tr√∫c, c√≥ th·ªÉ c·∫ßn model ph·ª©c t·∫°p h∆°n\")\n",
    "\n",
    "# 4. Heteroscedasticity (visual check)\n",
    "print(f\"\\n4. Heteroscedasticity (visual):\")\n",
    "print(\"   ‚Üí Xem Plot 1: Residuals Over Time\")\n",
    "print(\"   ‚Üí N·∫øu ph∆∞∆°ng sai kh√¥ng ƒë·ªïi theo th·ªùi gian = homoscedastic (good)\")\n",
    "print(\"   ‚Üí N·∫øu ph∆∞∆°ng sai thay ƒë·ªïi theo th·ªùi gian = heteroscedastic (bad)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bf825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final assessment\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä T·ªîNG K·∫æT CH·∫®N ƒêO√ÅN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "checks = {\n",
    "    'Mean ‚âà 0': abs(residuals.mean()) < 0.1 * residuals.std(),\n",
    "    'Normal distribution': jb_pvalue > 0.05,\n",
    "    'No autocorrelation': (lb_test['lb_pvalue'] > 0.05).all(),\n",
    "}\n",
    "\n",
    "passed = sum(checks.values())\n",
    "total = len(checks)\n",
    "\n",
    "for check, result in checks.items():\n",
    "    print(f\"{'‚úÖ' if result else '‚ùå'} {check}\")\n",
    "\n",
    "print(f\"\\nPassed: {passed}/{total}\")\n",
    "\n",
    "if passed == total:\n",
    "    print(\"\\nüéâ XU·∫§T S·∫ÆC! Model ƒë√£ b·∫Øt ƒë∆∞·ª£c c·∫•u tr√∫c ch√≠nh c·ªßa chu·ªói\")\n",
    "    print(\"   ‚Üí Residuals ‚âà white noise\")\n",
    "    print(\"   ‚Üí Model s·∫µn s√†ng ƒë·ªÉ forecast\")\n",
    "elif passed >= total - 1:\n",
    "    print(\"\\n‚úÖ T·ªêT! Model t∆∞∆°ng ƒë·ªëi t·ªët\")\n",
    "    print(\"   ‚Üí C√≥ th·ªÉ d√πng ƒë·ªÉ forecast, nh∆∞ng c√≥ th·ªÉ c·∫£i thi·ªán\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è C·∫¶N C·∫¢I THI·ªÜN! Model ch∆∞a t·ªëi ∆∞u\")\n",
    "    print(\"   ‚Üí Residuals v·∫´n c√≥ structure\")\n",
    "    print(\"   ‚Üí Xem x√©t:\")\n",
    "    print(\"      ‚Ä¢ Th·ª≠ (p,d,q) kh√°c\")\n",
    "    print(\"      ‚Ä¢ Th√™m seasonal component (SARIMA)\")\n",
    "    print(\"      ‚Ä¢ Xem x√©t model kh√°c (GARCH cho volatility, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31affc87",
   "metadata": {},
   "source": [
    "## BONUS: Forecast v·ªõi Model T·ªët Nh·∫•t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "n_forecast = len(test)\n",
    "forecast = best_fitted.forecast(steps=n_forecast)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(test[VALUE_COL], forecast))\n",
    "mae = mean_absolute_error(test[VALUE_COL], forecast)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FORECAST PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Model: ARIMA{best_order_aic}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Plot train (last 1000 points)\n",
    "train_plot = train[VALUE_COL].iloc[-1000:]\n",
    "ax.plot(train_plot.index, train_plot.values, label='Train (last 1000)', linewidth=1, color='blue')\n",
    "\n",
    "# Plot test\n",
    "ax.plot(test.index, test[VALUE_COL].values, label='Actual', linewidth=1.5, color='green')\n",
    "\n",
    "# Plot forecast\n",
    "ax.plot(test.index, forecast.values, label=f'Forecast ARIMA{best_order_aic}', \n",
    "        linewidth=1.5, color='red', linestyle='--')\n",
    "\n",
    "ax.axvline(x=test.index[0], color='black', linestyle='--', linewidth=2, alpha=0.5, label='Train/Test split')\n",
    "ax.set_xlabel('Time', fontsize=11)\n",
    "ax.set_ylabel(VALUE_COL, fontsize=11)\n",
    "ax.set_title(f'Forecast vs Actual - ARIMA{best_order_aic}', fontsize=13, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d362ae5a",
   "metadata": {},
   "source": [
    "## üìù T√ìM T·∫ÆT QUY TR√åNH ARIMA\n",
    "\n",
    "### ‚úÖ 5 B∆Ø·ªöC RA QUY·∫æT ƒê·ªäNH:\n",
    "\n",
    "**B∆Ø·ªöC 1: QUAN S√ÅT CHU·ªñI G·ªêC**\n",
    "- V·∫Ω ƒë·ªì th·ªã, th√™m moving average\n",
    "- Nh·∫≠n di·ªán xu h∆∞·ªõng (trend) v√† m√πa v·ª• (seasonality)\n",
    "- Quy·∫øt ƒë·ªãnh: C√≥ c·∫ßn seasonal component kh√¥ng?\n",
    "\n",
    "**B∆Ø·ªöC 2: KI·ªÇM ƒê·ªäNH D·ª™NG - CH·ªåN d**\n",
    "- Ch·∫°y ADF test v√† KPSS test\n",
    "- N·∫øu kh√¥ng d·ª´ng ‚Üí differencing\n",
    "- Quy·∫øt ƒë·ªãnh: d = 0, 1, ho·∫∑c 2\n",
    "\n",
    "**B∆Ø·ªöC 3: XEM ACF/PACF - G·ª¢I √ù p v√† q**\n",
    "- Plot ACF v√† PACF c·ªßa chu·ªói sau differencing\n",
    "- T√¨m pattern cut-off ho·∫∑c decay\n",
    "- Quy·∫øt ƒë·ªãnh: Kho·∫£ng gi√° tr·ªã cho p v√† q (v√≠ d·ª•: p ‚â§ 3, q ‚â§ 3)\n",
    "\n",
    "**B∆Ø·ªöC 4: GRID SEARCH - T√åM (p,d,q) T·ªêI ∆ØU**\n",
    "- Th·ª≠ t·∫•t c·∫£ combinations trong kho·∫£ng\n",
    "- So s√°nh AIC/BIC\n",
    "- Quy·∫øt ƒë·ªãnh: (p,d,q) c√≥ AIC th·∫•p nh·∫•t\n",
    "\n",
    "**B∆Ø·ªöC 5: CH·∫®N ƒêO√ÅN PH·∫¶N D∆Ø**\n",
    "- Ki·ªÉm tra residuals: mean, normality, autocorrelation\n",
    "- Ljung-Box test\n",
    "- Quy·∫øt ƒë·ªãnh: Model ƒë·ªß t·ªët? Hay c·∫ßn th·ª≠ (p,d,q) kh√°c?\n",
    "\n",
    "### ‚ö†Ô∏è ƒêI·ªÇM QUAN TR·ªåNG:\n",
    "\n",
    "1. **Residuals ‚âà White Noise l√† m·ª•c ti√™u**\n",
    "   - Mean ‚âà 0\n",
    "   - No autocorrelation\n",
    "   - Normal distribution (t·ªët nh∆∞ng kh√¥ng b·∫Øt bu·ªôc)\n",
    "\n",
    "2. **AIC/BIC ch·ªâ l√† c√¥ng c·ª•**\n",
    "   - Kh√¥ng ph·∫£i c√†ng th·∫•p c√†ng t·ªët m·ªçi l√∫c\n",
    "   - ∆Øu ti√™n model ƒë∆°n gi·∫£n n·∫øu performance g·∫ßn nhau\n",
    "\n",
    "3. **Residual diagnostics l√† QUAN TR·ªåNG NH·∫§T**\n",
    "   - Model v·ªõi AIC th·∫•p nh·∫•t c√≥ th·ªÉ kh√¥ng t·ªët n·∫øu residuals k√©m\n",
    "   - Ki·ªÉm tra k·ªπ tr∆∞·ªõc khi d√πng forecast\n",
    "\n",
    "### üí° M·ªû R·ªòNG:\n",
    "\n",
    "N·∫øu ARIMA kh√¥ng ƒë·ªß t·ªët, xem x√©t:\n",
    "- **SARIMA**: Th√™m seasonal component (P,D,Q,s)\n",
    "- **ARIMAX**: Th√™m external regressors (bi·∫øn ngo·∫°i sinh)\n",
    "- **GARCH**: Model cho volatility clustering\n",
    "- **Prophet, LSTM**: C√°c ph∆∞∆°ng ph√°p hi·ªán ƒë·∫°i h∆°n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
